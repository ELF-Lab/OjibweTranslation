{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad0a6ea-56e4-4ded-80aa-4fd07bf57a90",
   "metadata": {},
   "source": [
    "## 01-VTA Pre-processing\n",
    "In this notebook, we will filter out and does some pre-processing with VTA verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b8069b-aee3-48b5-a190-67faa123d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install groq # groq package to connect to LLM API on groq.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e772a7cd-8b68-4e0b-860b-abd767608bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "# parse the json string\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8683b2dd-753d-447c-a29e-197013c843f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### First, we load the dictionary\n",
    "DATA_PATH = \"../../../data/\"\n",
    "filename = DATA_PATH + \"ob_en_dict.csv\"\n",
    "dict_df = pd.read_csv(filename)\n",
    "dict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e3596d-b563-4382-b4c8-332e987aad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_tag = \"vta\"\n",
    "df = dict_df.query(\"type.str.contains(@filter_tag)\")\n",
    "df = df.reset_index().drop(columns=\"index\")\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a471c75c-9a33-485a-aabd-12c7960d9654",
   "metadata": {},
   "source": [
    "### Using LLM to process meanings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4066f68f-aefc-4567-910e-b5b21fd3b03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary preview\n",
    "i = 200\n",
    "print(df.iloc[i][\"definition\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8eb978-ae33-4580-9d3e-f1cc1d76ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(1, '../') # LLM_api.py is in the parent folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3c8ea4-03bb-48bf-b812-94f278ccea1a",
   "metadata": {},
   "source": [
    "### Groq API key \n",
    "Please go to Groq.com to sign up and get an API key, put it into `src/01_data_preprocessing/env/credentials.json` as in the following format\n",
    "\n",
    "{\"GROQ_API_KEY\":\"your_api_key\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b24c9a7-ecd0-4d88-ad7e-bc0b4c9b5f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import LLM_api\n",
    "from LLM_api import hello, get_api_key, connect, send_request\n",
    "\n",
    "hello(\"API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3111e93e-86e6-4fe8-8c9b-c28f99c56e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = get_api_key()\n",
    "print(len(api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33957cd-334b-4f50-b144-f6aed6f89040",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = connect(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c3d1e9-a460-4b50-a7ed-1d326510c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"JSON What is the biggest city of New York state?\"\n",
    "send_request(s, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0494fc5-6541-4b25-9bc8-f6fe855959ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"A given definition example: d =  \"smudge, cense h/; smoke h/ (for preservation)\". \n",
    "Analyze the definition d. What is subject and object? Rewrite definition by replacing subject and object by literal `{{subject}}` and `{{object}}`.  \n",
    "Replace verbs to infinitive form (e.g. wants -> want, is -> be, gets -> get).\n",
    "Answer in form {\"verbs\":[], \"templates\":[]}. Split the definition for each main verb. \n",
    "Note the words like \"something\" or \"(it)\", don't parse them as \"{{object}}\", keep them as literal. \n",
    "Translate \"h/ or it\" to \"{{object}}\".\n",
    "Extract the main verbs only, if the sentence is in passive voice, the main verb is \"be\". The answer for definition d should be in JSON format \n",
    "output = {verbs:[\"smudge\", \"cense\", \"smoke\"],\"templates\":[\"{{subject}} smudge {{object}}\", \"{{subject}} cense {{object}}\", \"\"{{subject}} smoke {{object}} (for preservation)\"]}. \n",
    "Do not invent new verbs. Keep the new definitions literally close as the original definition. Keep things in brackets as literal, e.g. (it), (something) or (by someone). \n",
    "\n",
    "Bellow are more examples:\n",
    "\n",
    "Definition = pull h/ aboard\n",
    "Output = {'verbs': ['pull'], 'templates': ['{{subject}} pull {{object}} aboard']}\n",
    "--------------------\n",
    "Definition = fix, repair (it) for h/\n",
    "Output = {'verbs': ['fix', 'repair'], 'templates': ['{{subject}} fix (it) for {{object}}', '{{subject}} repair (it) for {{object}}']}\n",
    "--------------------\n",
    "Definition = throw h/ aboard\n",
    "Output = {'verbs': ['throw'], 'templates': ['{{subject}} throw {{object}} aboard']}\n",
    "--------------------\n",
    "Definition = cool h/ with water\n",
    "Output = {'verbs': ['cool'], 'templates': ['{{subject}} cool {{object}} with water']}\n",
    "--------------------\n",
    "Definition = cook it (animate)\n",
    "Output = {'verbs': ['cook'], 'templates': ['{{subject}} cook {{object}} (animate)']}\n",
    "--------------------\n",
    "Definition = throw (it) here to h/\n",
    "Output = {'verbs': ['throw'], 'templates': ['{{subject}} throw (it) here to {{object}}']}\n",
    "--------------------\n",
    "Definition = cut it (animate; sheet-like) short\n",
    "Output = {'verbs': ['cut'], 'templates': ['{{subject}} cut {{object}} ((animate; sheet-like) short ']}\n",
    "--------------------\n",
    "Definition = cut it (animate) so wide\n",
    "Output = {'verbs': ['cut'], 'templates': ['{{subject}} cut {{object}} (animate) so wide']}\n",
    "--------------------\n",
    "Definition = staunch h/ bleeding\n",
    "Output = {'verbs': ['staunch'], 'templates': ['{{subject}} staunch {{object}} bleeding']}\n",
    "--------------------\n",
    "Definition = ride mounted on top of h/; sit astride h/\n",
    "Output = {'verbs': ['ride', 'sit'], 'templates': ['{{subject}} ride mounted on top of {{object}}', '{{subject}} sit astride {{object}}']}\n",
    "--------------------\n",
    "Definition = warm something (liquid) up for h/\n",
    "Output = {'verbs': ['warm'], 'templates': ['{{subject}} warm something (liquid) up for {{object}}']}\n",
    "--------------------\n",
    "Definition = warm something for h/ at the fire\n",
    "Output = {'verbs': ['warm'], 'templates': ['{{subject}} warm something for {{object}} at the fire']}\n",
    "--------------------\n",
    "Definition = warm h/ foot or feet\n",
    "Output = {'verbs': ['warm'], 'templates': ['{{subject}} warm {{object-possessive}} foot or feet']}\n",
    "--------------------\n",
    "Definition = catch up to h/ following h/ tracks or trail\n",
    "Output = {'verbs': ['catch'], 'templates': ['{{subject}} catch up to {{object}} following {{object-possessive}} tracks or trail']}\n",
    "--------------------\n",
    "Definition = dye, color h/ or it (animate)\n",
    "Output = {'verbs': ['dye', 'color'], 'templates': ['{{subject}} dye {{object}} (animate)', '{{subject}} color {{object}} (animate)']}\n",
    "--------------------\n",
    "Definition = dye, color (it) for h/\n",
    "Output = {'verbs': ['dye', 'color'], 'templates': ['{{subject}} dye (it) for {{object}}', '{{subject}} color (it) for {{object}}']}\n",
    "--------------------\n",
    "\n",
    "Now process a new definition\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657013ab-0e37-4e42-9102-9412a2fb5934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_def = \"warm it (animate; mineral), heat it (animate; mineral) up\"\n",
    "word_def = \"dye, color h/ (animate)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e50234-925c-4153-983d-79ded4d35288",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(word_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a3b684-2d4b-4ea9-a422-c933eb6d8c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{prompt_template}: \"{word_def}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c1ac1a-8e25-44f7-a0b7-6f75c9f24d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = send_request(f'{prompt_template} \"{word_def}\"', llm)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34368bab-84fb-4998-a765-5777ef996c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_json_format(json_obj):\n",
    "    \"\"\"\n",
    "        Check if the Json object format is valid ({\"verbs\" : [], \"templates\" : []}\n",
    "    \"\"\"\n",
    "    result = False\n",
    "    if type(json_obj) != dict:\n",
    "        print(\"Wrong data type, expecting json dict object\")\n",
    "        return False\n",
    "\n",
    "    if len(json_obj.keys()) != 2:\n",
    "        print(\"Wrong keys, expecting 2 keys\")\n",
    "        return False\n",
    "\n",
    "    if set(json_obj.keys()) != {\"verbs\", \"templates\"}:\n",
    "        print(set(json_obj.keys()))\n",
    "        print(\"Wrong keys items, expecting verbs and templates\")\n",
    "        return False\n",
    "\n",
    "    if (json_obj[\"verbs\"] is None or \n",
    "        type(json_obj[\"verbs\"]) != list or\n",
    "        len(json_obj[\"verbs\"]) <= 0\n",
    "       ):\n",
    "        print(\"Wrong verbs, expecting at least 1 verb\")\n",
    "        return False\n",
    "        \n",
    "    if (json_obj[\"templates\"] is None or \n",
    "        type(json_obj[\"templates\"]) != list or\n",
    "        len(json_obj[\"templates\"]) <= 0\n",
    "       ):\n",
    "        print(\"Wrong templates, expecting at least 1 template\")\n",
    "        return False\n",
    "\n",
    "    for template in json_obj[\"templates\"]:\n",
    "        # look for invalid slots such as {{subject}}, {{distance}}, etc\n",
    "        r = \"({{[\\w|-]+}})\"\n",
    "        slots = re.findall(r, template)\n",
    "        vai_slots = {\"{{subject}}\", \"{{object}}\", \"{{object-possessive}}\"} # slots fro VTA verbs\n",
    "        if len(set(slots).difference(vai_slots)) > 0: \n",
    "            print(\"Wrong slots in template =\", slots)\n",
    "            return False\n",
    "            \n",
    "\n",
    "    # passed all condition\n",
    "    result = True\n",
    "    return result\n",
    "\n",
    "assert check_json_format(dict()) == False\n",
    "assert check_json_format({\"verbs\":[\"verb\"], \"templates\":[\"template 1\", \"template 2\"]}) == True\n",
    "assert check_json_format({\"verbs\":[], \"templates\":[\"template 1\", \"template 2\"]}) == False\n",
    "assert check_json_format({\"verbs\":[\"verb1\", \"verb2\"], \"templates\":[\"template 1\", \"template 2\"]}) == True\n",
    "assert check_json_format({\"verbs\":[\"verb1\"], \"templates\":[], \"something else\":[]}) == False\n",
    "assert check_json_format({\"verbs\":[\"verb1\"], \"templates\":[], \"POS\":[]}) == False\n",
    "assert check_json_format({\"verbs\":[\"verb1\"], \"templates\":[\"{{subject}} see {{object}}\"]}) == True\n",
    "assert check_json_format({\"verbs\":[\"verb1\"], \"templates\":[\"{{subject}} is hungry\"]}) == True\n",
    "assert check_json_format({\"verbs\":[\"verb1\"], \"templates\":[\"{{subject}} buy it for {{object}}\"]}) == True\n",
    "assert check_json_format({\"verbs\":[\"verb1\"], \"templates\":[\"{{subject}} buy it for {{adjective}}\"]}) == False\n",
    "assert check_json_format({\"verbs\":[\"verb1\"], \"templates\":[\"they warm {{object-possessive}} feet at the fire\"]}) == True\n",
    "\n",
    "\n",
    "print(\"Passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa0a24e-8c92-44e3-b093-a757b1d201a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2json(s):\n",
    "    \"\"\"\n",
    "        convert string to json format and check if the format is valid \n",
    "    \"\"\"\n",
    "    result = 0\n",
    "    # clean and remove \\n\n",
    "    s = s.strip().replace(\"\\n\", \"\") \n",
    "    # extract {...} using regex\n",
    "    re_str = r\"{.*}\"\n",
    "    json_str = \"\"\n",
    "    try:\n",
    "        json_str = re.findall(re_str, s)[0]\n",
    "        result = json.loads(json_str)\n",
    "\n",
    "        if check_json_format(result):\n",
    "            print(\"JSON format check OK\")\n",
    "        else:\n",
    "            print(f\"Wrong JSON format. Item = \\n{result}\")\n",
    "            return \"\"\n",
    "    except:\n",
    "        print(\"Error parsing json =\", json_str)\n",
    "        return \"\"\n",
    "\n",
    "    return result\n",
    "    \n",
    "ex = str2json(result)\n",
    "print(ex)\n",
    "print(ex['verbs'])\n",
    "print(ex['templates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72d5776-bf55-4bad-826c-485ef83309fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try a more complex example\n",
    "s = \"attach it (animate) (using something); sew it (animate) on\"\n",
    "str2json(send_request(f'{prompt_template}: \"{s}\"', llm))['templates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d59155-416f-4f8a-b051-fb3a8e6c2ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create place holder column\n",
    "df[\"llm_templates\"] = df[\"definition\"].apply(lambda x: \"\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cfada0-e18d-48b2-b9db-3484bfdd97b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_func = lambda text: str2json(send_request(f'{prompt_template}: \"{text}\"', llm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a502c661-1c48-4d53-b83c-209de5a61f95",
   "metadata": {},
   "source": [
    "### Sampling data for few-shot training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5557ea-c59c-44d6-a8b8-ef3ceb699d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.sample(n=10, random_state=42)\n",
    "for i in range(len(tmp)):\n",
    "    item = tmp.iloc[i]\n",
    "    print(\"Lemma =\", item[\"lemma\"])\n",
    "    print(\"Definition =\", item[\"definition\"])\n",
    "    print(\"Type =\", item[\"type\"])\n",
    "    print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603c8dab-5913-4360-a1d1-a596b1658f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Running on the sampled set, used for few-shot learning...\")\n",
    "for i in range(len(tmp)):\n",
    "    item = tmp.iloc[i]\n",
    "    print(\"Lemma =\", item[\"lemma\"])\n",
    "    print(\"Definition =\", item[\"definition\"])\n",
    "    print(\"Type =\", item[\"type\"])\n",
    "\n",
    "    parsed_item = llm_func(tmp.iloc[i][\"definition\"].strip().lower())\n",
    "\n",
    "    print(\"Output =\", parsed_item)\n",
    "    print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651e1c29-2dbb-4f3e-be08-3a96c97fc074",
   "metadata": {},
   "source": [
    "##### We will manually adjust the templates and put back into the prompt\n",
    "When all output for sampled set look good, we will proceed to the actual dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ab14dd-1f29-481c-a8e7-f71a8edbf644",
   "metadata": {},
   "source": [
    "### Actual processing on the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0bb05a-3252-4b53-a24d-54507615e3d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = len(df)\n",
    "print(\"Len df =\", n)\n",
    "max_row = n # set to n for full set\n",
    "\n",
    "error_count = 0\n",
    "start_id = 20 if max_row < n else 0 # for debug purpose\n",
    "\n",
    "for i in range(start_id, max_row):\n",
    "    # save check-point data\n",
    "    if (i+1) % 50 == 0:\n",
    "        print(\"Writing checkpoint...\")\n",
    "        output_filename = DATA_PATH + \"vta_dict_checkpoint.csv\"\n",
    "        df.to_csv(output_filename,\n",
    "                  index=False\n",
    "                  )\n",
    "        print(\"OK\")\n",
    "    \n",
    "    print(f\"Processing row {i+1} / {max_row}, {(i+1)*100/max_row:.0f} %\")\n",
    "    if df.iloc[i][\"llm_templates\"] != \"\":\n",
    "        print(\"Already processed. Skipping...\")\n",
    "        print(\"-----------------------------\")\n",
    "        continue\n",
    "        \n",
    "    parsed_item = llm_func(df.iloc[i][\"definition\"].strip().lower())\n",
    "    \n",
    "    if parsed_item == \"\":\n",
    "        # error parsing?\n",
    "        print(\"Error parsing result\")\n",
    "        error_count += 1\n",
    "        print(\"Error count so far =\", error_count)\n",
    "        \n",
    "    print(\"\\tDefinition =\", df.iloc[i][\"definition\"])\n",
    "    print(\"\\tInput =\", df.iloc[i][\"definition\"])    \n",
    "    print(\"\\tParsed =\", parsed_item)\n",
    "    print(\"-----------------------------\")\n",
    "    df.at[i, \"llm_templates\"] = parsed_item\n",
    "    \n",
    "print(\"Completed\")\n",
    "print(\"Error count =\", error_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59203542-888d-4de5-93a4-0cd7ec853829",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check for empty result\n",
    "count = 0\n",
    "for i in range(len(df)):\n",
    "    if df.iloc[i][\"llm_templates\"] == \"\" or 'templates' not in df.iloc[i][\"llm_templates\"].keys():\n",
    "        count += 1\n",
    "        print(\"Id =\", i)\n",
    "        print(\"Definition =\", df.iloc[i][\"definition\"])\n",
    "        print(\"LLM parsed text =\", df.iloc[i][\"llm_templates\"])\n",
    "        print(\"-----------------\")\n",
    "\n",
    "print(\"Total count =\", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa26a5c-0c7a-4ccb-87e5-dbd4d8342c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retry failed examples\n",
    "error_count = 0\n",
    "\n",
    "for i in range(max_row):\n",
    "    if df.iloc[i][\"llm_templates\"] != \"\":\n",
    "        continue\n",
    "        \n",
    "    parsed_item = llm_func(df.iloc[i][\"definition\"].strip().lower())\n",
    "    \n",
    "    if parsed_item == \"\":\n",
    "        # error parsing?\n",
    "        print(\"Error parsing result\")\n",
    "        error_count += 1\n",
    "        print(\"Error count so far =\", error_count)\n",
    "        \n",
    "    print(\"\\tDefinition =\", df.iloc[i][\"definition\"])\n",
    "    print(\"\\tParsed =\", parsed_item)\n",
    "    print(\"-----------------------------\")\n",
    "    df.at[i, \"llm_templates\"] = parsed_item\n",
    "    \n",
    "print(\"Completed\")\n",
    "print(\"Error count =\", error_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43ac51e-ecfc-43e0-a409-07eb670685d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check how many empty output\n",
    "df.query(\"llm_templates == ''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400c8e51-4c83-42e4-8b9f-febc92ffba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = DATA_PATH + \"vta_dict.csv\"\n",
    "df.to_csv(output_filename,\n",
    "          index=False\n",
    "          )\n",
    "\n",
    "output_filename = DATA_PATH + \"vta_dict.json\"\n",
    "df.to_json(output_filename,\n",
    "          orient=\"records\"\n",
    "          )\n",
    "\n",
    "\n",
    "print(\"Completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
